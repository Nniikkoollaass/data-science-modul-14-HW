{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nniikkoollaass/data-science-modul-14-HW/blob/main/DS_HW_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av8vuAyFfte1"
      },
      "source": [
        "Завдання\n",
        "\n",
        "\n",
        "\n",
        "В якості домашнього завдання вам пропонується створити рекурентну нейронну мережу за допомогою механізмів Keras, яка буде класифікувати рецензії із датасету imdb.\n",
        "\n",
        "\n",
        "\n",
        "На відміну від прикладу в модулі 9 ми використаємо рекурентну нейронну мережу. Поекспериментуйте з будовою мережі - RNN, LSTM, двостороння та глибока.\n",
        "\n",
        "\n",
        "\n",
        "Порівняйте результати та зробіть висновки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DPlUfvHhAGG",
        "outputId": "a860381d-eece-4605-c834-2794f873e057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 500)\n",
            "x_test shape: (25000, 500)\n",
            "Training Simple RNN model...\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 75s 118ms/step - loss: 0.5891 - accuracy: 0.6690 - val_loss: 0.4797 - val_accuracy: 0.7764\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 73s 116ms/step - loss: 0.3725 - accuracy: 0.8421 - val_loss: 0.4104 - val_accuracy: 0.8330\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.2255 - accuracy: 0.9115 - val_loss: 0.4361 - val_accuracy: 0.8288\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 67s 108ms/step - loss: 0.1130 - accuracy: 0.9626 - val_loss: 0.5079 - val_accuracy: 0.8220\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 67s 108ms/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.6001 - val_accuracy: 0.8152\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.1208 - accuracy: 0.9513 - val_loss: 0.5635 - val_accuracy: 0.7658\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3453 - accuracy: 0.8447 - val_loss: 0.6484 - val_accuracy: 0.6660\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.2812 - accuracy: 0.8794 - val_loss: 0.5952 - val_accuracy: 0.7900\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.1126 - accuracy: 0.9569 - val_loss: 0.6450 - val_accuracy: 0.7718\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.0524 - accuracy: 0.9819 - val_loss: 0.6907 - val_accuracy: 0.8094\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 0.7254 - accuracy: 0.7937\n",
            "Test accuracy of Simple RNN model: 0.7937\n",
            "\n",
            "Training LSTM model...\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 102s 160ms/step - loss: 0.4286 - accuracy: 0.7975 - val_loss: 0.3200 - val_accuracy: 0.8678\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 103s 165ms/step - loss: 0.2431 - accuracy: 0.9051 - val_loss: 0.3636 - val_accuracy: 0.8428\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 103s 165ms/step - loss: 0.1752 - accuracy: 0.9370 - val_loss: 0.3334 - val_accuracy: 0.8814\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 101s 162ms/step - loss: 0.3531 - accuracy: 0.8376 - val_loss: 0.4030 - val_accuracy: 0.8242\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 104s 166ms/step - loss: 0.1736 - accuracy: 0.9390 - val_loss: 0.3672 - val_accuracy: 0.8676\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 99s 159ms/step - loss: 0.1034 - accuracy: 0.9648 - val_loss: 0.3861 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 100s 160ms/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.4506 - val_accuracy: 0.8632\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 99s 159ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 0.5207 - val_accuracy: 0.8602\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 100s 160ms/step - loss: 0.0783 - accuracy: 0.9743 - val_loss: 0.5230 - val_accuracy: 0.8552\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 101s 161ms/step - loss: 0.0476 - accuracy: 0.9859 - val_loss: 0.5992 - val_accuracy: 0.8552\n",
            "782/782 [==============================] - 34s 43ms/step - loss: 0.5852 - accuracy: 0.8538\n",
            "Test accuracy of LSTM model: 0.8538\n",
            "\n",
            "Training Bidirectional LSTM model...\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 179s 282ms/step - loss: 0.4528 - accuracy: 0.7831 - val_loss: 0.3827 - val_accuracy: 0.8356\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 177s 283ms/step - loss: 0.2593 - accuracy: 0.9010 - val_loss: 0.3518 - val_accuracy: 0.8558\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 176s 281ms/step - loss: 0.1934 - accuracy: 0.9309 - val_loss: 0.3297 - val_accuracy: 0.8638\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 175s 280ms/step - loss: 0.1505 - accuracy: 0.9459 - val_loss: 0.4523 - val_accuracy: 0.8556\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 175s 280ms/step - loss: 0.1246 - accuracy: 0.9569 - val_loss: 0.4139 - val_accuracy: 0.8544\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 176s 282ms/step - loss: 0.1186 - accuracy: 0.9575 - val_loss: 0.4117 - val_accuracy: 0.8590\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 178s 286ms/step - loss: 0.1784 - accuracy: 0.9326 - val_loss: 0.4894 - val_accuracy: 0.8586\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 180s 287ms/step - loss: 0.0918 - accuracy: 0.9685 - val_loss: 0.4463 - val_accuracy: 0.8660\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 176s 282ms/step - loss: 0.0696 - accuracy: 0.9771 - val_loss: 0.4880 - val_accuracy: 0.8560\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 176s 282ms/step - loss: 0.0672 - accuracy: 0.9782 - val_loss: 0.5080 - val_accuracy: 0.8540\n",
            "782/782 [==============================] - 56s 71ms/step - loss: 0.5445 - accuracy: 0.8426\n",
            "Test accuracy of Bidirectional LSTM model: 0.8426\n",
            "\n",
            "Training Deep LSTM model...\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 207s 326ms/step - loss: 0.4023 - accuracy: 0.8146 - val_loss: 0.3249 - val_accuracy: 0.8656\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 210s 335ms/step - loss: 0.2336 - accuracy: 0.9130 - val_loss: 0.3043 - val_accuracy: 0.8808\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 206s 329ms/step - loss: 0.2946 - accuracy: 0.8751 - val_loss: 0.3800 - val_accuracy: 0.8424\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 206s 329ms/step - loss: 0.2098 - accuracy: 0.9222 - val_loss: 0.3570 - val_accuracy: 0.8476\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 196s 314ms/step - loss: 0.1807 - accuracy: 0.9298 - val_loss: 0.5464 - val_accuracy: 0.7624\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 205s 328ms/step - loss: 0.2289 - accuracy: 0.9111 - val_loss: 0.3975 - val_accuracy: 0.8474\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 203s 326ms/step - loss: 0.2259 - accuracy: 0.9107 - val_loss: 0.4186 - val_accuracy: 0.8476\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 203s 325ms/step - loss: 0.1327 - accuracy: 0.9543 - val_loss: 0.4205 - val_accuracy: 0.8588\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 203s 326ms/step - loss: 0.0901 - accuracy: 0.9705 - val_loss: 0.4431 - val_accuracy: 0.8648\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 205s 328ms/step - loss: 0.0678 - accuracy: 0.9778 - val_loss: 0.4957 - val_accuracy: 0.8600\n",
            "782/782 [==============================] - 69s 89ms/step - loss: 0.5339 - accuracy: 0.8510\n",
            "Test accuracy of Deep LSTM model: 0.8510\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, LSTM, Dense, Bidirectional\n",
        "\n",
        "# Завантаження даних\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "# Побудова моделі з Simple RNN\n",
        "def build_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32, input_length=maxlen))\n",
        "    model.add(SimpleRNN(32))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Побудова моделі з LSTM\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32, input_length=maxlen))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Побудова двосторонньої LSTM моделі\n",
        "def build_bidirectional_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32, input_length=maxlen))\n",
        "    model.add(Bidirectional(LSTM(32)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Побудова глибокої LSTM моделі\n",
        "def build_deep_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32, input_length=maxlen))\n",
        "    model.add(LSTM(32, return_sequences=True))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Тренування та оцінка моделей\n",
        "models = {\n",
        "    'Simple RNN': build_rnn_model(),\n",
        "    'LSTM': build_lstm_model(),\n",
        "    'Bidirectional LSTM': build_bidirectional_lstm_model(),\n",
        "    'Deep LSTM': build_deep_lstm_model()\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f'Training {model_name} model...')\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    print(f'Test accuracy of {model_name} model: {acc:.4f}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDfGN2A3hPML"
      },
      "source": [
        "Опис коду:\n",
        "\n",
        "Завантаження даних:\n",
        "Ми завантажуємо датасет IMDB та обмежуємо кількість слів (максимум 10,000 найбільш вживаних слів). Потім ми доповнюємо (паддуємо) рецензії, щоб вони всі були однакової довжини (500 слів).\n",
        "\n",
        "Побудова моделей:\n",
        "\n",
        "Simple RNN:\n",
        "Використовує рекурентний шар (SimpleRNN).\n",
        "\n",
        "LSTM:\n",
        "Використовує шар довготривалої пам'яті (LSTM).\n",
        "\n",
        "Bidirectional LSTM:\n",
        "Використовує двосторонній шар LSTM (Bidirectional LSTM).\n",
        "\n",
        "Deep LSTM:\n",
        "Використовує два LSTM шари для побудови глибокої моделі.\n",
        "\n",
        "Тренування та оцінка:\n",
        "Кожну модель тренуємо протягом 10 епох на тренувальних даних з використанням валідаційного спліту 0.2.\n",
        "\n",
        "Потім оцінюємо модель на тестових даних та виводимо точність."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Порівняння результатів моделей RNN, LSTM, двосторонньої LSTM та глибокої LSTM\n",
        "\n",
        "\n",
        "1. Simple RNN\n",
        "\n",
        "\n",
        "Точність на тестових даних: 0.7937\n",
        "Переваги: Простота реалізації, менша кількість обчислень і параметрів.\n",
        "Недоліки: Можливість забування інформації через проблеми з градієнтами (ванішинг градієнт), особливо для довгих послідовностей.\n",
        "\n",
        "\n",
        "2. LSTM\n",
        "\n",
        "\n",
        "Точність на тестових даних: 0.8538\n",
        "Переваги: Краще зберігання довгострокової інформації завдяки використанню комірок пам'яті, здатність моделювати довгі залежності.\n",
        "Недоліки: Більш складна архітектура, більше обчислень і параметрів.\n",
        "\n",
        "\n",
        "3. Bidirectional LSTM\n",
        "\n",
        "\n",
        "Точність на тестових даних: 0.8426\n",
        "Переваги: Краще захоплення контексту, оскільки використовує інформацію як з минулого, так і з майбутнього.\n",
        "Недоліки: Більша складність і вимоги до обчислень, можуть бути обмеження через пам'ять та час тренування.\n",
        "\n",
        "\n",
        "4. Deep LSTM\n",
        "\n",
        "\n",
        "Точність на тестових даних: 0.8510\n",
        "Переваги: Більш глибока архітектура може захоплювати складніші патерни в даних, потенційно кращі результати для складних завдань.\n",
        "Недоліки: Вимагає більше часу на тренування та більше пам'яті, ризик перенавчання на невеликих датасетах.\n",
        "\n",
        "\n",
        "Висновки\n",
        "\n",
        "\n",
        "Проста RNN показала найгірший результат серед всіх моделей з точністю 79.37%. Це очікувано, оскільки проста RNN має обмеження в запам'ятовуванні довгострокової інформації.\n",
        "\n",
        "\n",
        "LSTM показала найвищу точність серед всіх моделей - 85.38%, що свідчить про її здатність добре моделювати довгострокові залежності.\n",
        "\n",
        "\n",
        "Bidirectional LSTM має трохи меншу точність (84.26%) порівняно з LSTM, що може бути через більш високу складність моделі і можливо недостатнє налаштування гіперпараметрів.\n",
        "\n",
        "\n",
        "Deep LSTM також показала високу точність (85.10%), що демонструє її здатність захоплювати складніші патерни. Однак, вона незначно поступається звичайній LSTM, що може свідчити про перенавчання або недостатнє налаштування.\n",
        "\n",
        "\n",
        "Загалом, LSTM моделі показують кращі результати в задачі класифікації рецензій IMDB, що підтверджує їх переваги в роботі з послідовними даними. Використання двосторонньої та глибокої архітектур може покращити результати, але вимагає більш обережного налаштування і більших обчислювальних ресурсів."
      ],
      "metadata": {
        "id": "et6fl9uKm0fr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM1C3Lex0eIuJyFZ1cJmwA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}